{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "os.environ['CUDAIDX'] = 'cuda:2'\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=xxx\n",
    "%env OPENAI_API_BASE=xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.core.display import HTML\n",
    "from functools import partial\n",
    "\n",
    "from engine.utils import ProgramGenerator, ProgramInterpreter\n",
    "from prompts.magicbrush import MAGICBRUSH_CURATED_EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = ProgramInterpreter(dataset='magicbrush')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(inputs,num_prompts=8,method='random',seed=42,group=0):\n",
    "    if method=='all':\n",
    "        prompt_examples = MAGICBRUSH_CURATED_EXAMPLES\n",
    "    elif method=='random':\n",
    "        random.seed(seed)\n",
    "        prompt_examples = random.sample(MAGICBRUSH_CURATED_EXAMPLES,num_prompts)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    prompt_examples = '\\n'.join(prompt_examples)\n",
    "    prompt_examples = f\"\"\"Considering the examples provided:\\n\\n\n",
    "    {prompt_examples}\n",
    "    \"\"\"\n",
    "    return prompt_examples + \"\\nInstruction: {instruction}\\nProgram:\".format(**inputs)\n",
    "\n",
    "prompter = partial(create_prompt,method='all')\n",
    "generator = ProgramGenerator(prompter=prompter,dataset='magicbrush')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from .utils.image_eval import eval_distance, eval_clip_i, eval_clip_t\n",
    "import clip\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from transformers import CLIPModel, ViTModel\n",
    "\n",
    "evaluation = 'l1,l2,clip-i,dino,clip-t'\n",
    "evaluation = 'l1,l2,clip-i,dino'\n",
    "device = os.environ.get('CUDAIDX', 'cuda:0')\n",
    "\n",
    "from tqdm import tqdm\n",
    "test_file = os.path.join(Path.home(), 'codes/ExoViP/datasets/magicbrush/test.json')\n",
    "with open(test_file) as jp:\n",
    "    test = json.load(jp)\n",
    "    \n",
    "eval_pred = 0\n",
    "eval_cnt = 0\n",
    "\n",
    "result_dir = os.path.join(Path.home(), 'codes/ExoViP/results/magicbrush/')\n",
    "if not os.path.exists(result_dir): \n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "result_pairs = []\n",
    "cnt = 0\n",
    "\n",
    "for idx, dct in tqdm(test.items()):\n",
    "    source_img = dct['source']\n",
    "    source_img_path = os.path.join(Path.home(), 'codes/ExoViP/datasets/magicbrush/imgs', source_img)\n",
    "    source_image = Image.open(source_img_path)\n",
    "    source_image.thumbnail((512, 512),Image.Resampling.LANCZOS)\n",
    "    target_img = dct['target']\n",
    "    target_img_path = os.path.join(Path.home(), 'codes/ExoViP/datasets/magicbrush/imgs', target_img)\n",
    "    # target_image = Image.open(target_img_path)\n",
    "    # target_image.thumbnail((512, 512),Image.Resampling.LANCZOS)\n",
    "    init_state = dict(\n",
    "        IMAGE=source_image.convert('RGB'),\n",
    "        CT_SCORE=0\n",
    "    )\n",
    "    instruction = dct['instruction']\n",
    "    \n",
    "    results = []\n",
    "    ct_scores = []\n",
    "    initial_prompts = []\n",
    "    initial_prompts.append(generator.generate_prompt(dict(instruction=instruction)))\n",
    "    prompt_examples = MAGICBRUSH_CURATED_EXAMPLES\n",
    "    pre_instruct = \"Think step by step to carry out the instruction. \\\n",
    "            while taking rejected solutions into account and learning from them. Here are evaluated solutions that were rejected: {rejected_solutions}\\n\\n \\\n",
    "                Answer the question without making the same mistakes you did with the evaluated rejected solutions. Be simple, Be direct, don't repeat or reply other thing \\n\\n \\\n",
    "                    Applicable modules include: SEG, SELECT, REPLACE, RESULT \\\n",
    "                        Following the examples provided:\\n\\n\"\n",
    "    \n",
    "    # prog,_ = generator.generate(instruction)\n",
    "    # print(instruction)\n",
    "    # print(prog)\n",
    "    # cnt += 1\n",
    "    # if cnt < 4: continue\n",
    "    # result, prog_state = interpreter.execute(prog, init_state, inspect=False)\n",
    "\n",
    "#     prog,_ = generator.generate(dict(instruction=instruction))\n",
    "#     result, prog_state = interpreter.execute(prog, init_state, inspect=False)\n",
    "    \n",
    "    # result, ct_score, cd_score = interpreter.aug_execute(initial_prompts, init_state, instruction, pre_instruct, prompt_examples, task='magicbrush')\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        result, ct_score, cd_score = interpreter.aug_execute(initial_prompts, init_state, instruction, pre_instruct, prompt_examples, task='magicbrush')\n",
    "        if result == 'NA': result = source_image\n",
    "        # prog,_ = generator.generate(dict(instruction=instruction))\n",
    "        # result, prog_state = interpreter.execute(prog, init_state, inspect=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = source_image\n",
    "        # continue\n",
    "    \n",
    "    result_path = os.path.join(result_dir, idx+'.png')\n",
    "    result.save(result_path)\n",
    "    \n",
    "    result_pairs.append((result_path, target_img_path))\n",
    "    \n",
    "    # if cnt>4: break\n",
    "\n",
    "# distance\n",
    "if 'l1' in evaluation:\n",
    "    l1_score = eval_distance(result_pairs, 'l1')\n",
    "    print('l1: ', l1_score)\n",
    "if 'l2' in evaluation:\n",
    "    l2_score = eval_distance(result_pairs, 'l2')\n",
    "    print('l2: ', l2_score)\n",
    "# quality\n",
    "if 'clip-i' in evaluation:\n",
    "    model = CLIPModel.from_pretrained('openai/clip-vit-base-patch32').to(device)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=3),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    # model, transform = clip.load(\"ViT-B/32\", device)\n",
    "    # print(\"CLIP-I model loaded: \", model)\n",
    "    clip_i_score = eval_clip_i(result_pairs, model, transform, device)\n",
    "    print('clip-i: ', clip_i_score)\n",
    "if 'dino' in evaluation:\n",
    "    # model = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "    model = ViTModel.from_pretrained('facebook/dino-vits16')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=3),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    dino_score = eval_clip_i(result_pairs, model, transform, device, metric='dino')\n",
    "    print('dino: ', dino_score)\n",
    "if 'clip-t' in evaluation:\n",
    "    # model, transform = clip.load(\"ViT-B/32\", device)\n",
    "    model = CLIPModel.from_pretrained('openai/clip-vit-base-patch32').to(device)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=3),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    clip_t_score, final_turn_oracle_score = eval_clip_t(result_pairs, model, transform, device)\n",
    "    print('clip-t', clip_t_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6aae81381dc24e2fd0d8778e266667bb8dbd7e1c04425e21584f774a2d20c40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
